import torch
import torch.nn as nn
from tdnn import TDNN as TDNNLayer
from samples_from_web.sample1 import sample1
from samples_from_web.sample2 import sample2
from samples_from_web.sample3 import sample3

sample = sample1
logged = True
normed = True


class TDNNv1(nn.Module):
    '''
    TDNN Model from Paper, consisting of the following layers:
    - tdnn 1: 16 in channels, 8 out channels, 15 samples, window of 3
    - sigmoid after tdnn
    - tdnn 2: 8 in channels, 3 out channels, 13 samples, window of 5
    - sigmoid after tdnn
    - flatten: 9 frequencies, 3 out channels, flattens to (27, ) array
    - linear: 27 inputs, 4 outputs
    '''

    def __init__(self):
        super(TDNNv1, self).__init__()

        self.tdnn1 = TDNNLayer(16, 8, [-1,0,1])
        self.sigmoid1 = nn.Sigmoid()
        self.tdnn2 = TDNNLayer(8, 3, [-2,0,2])
        self.sigmoid2 = nn.Sigmoid()
        self.flatten = nn.Flatten()
        self.linear = nn.Linear(27, 4)
        self.network = nn.Sequential(
            self.tdnn1,
            self.sigmoid1,
            self.tdnn2,
            self.sigmoid2,
            self.flatten,
            self.linear,
        )

    def forward(self, x):
        out = self.network(x)
        return out

model = TDNNv1()

tdnn1Weight = [[4.062817692756652832e-01,3.391667008399963379e-01,3.720203042030334473e-01,6.213076785206794739e-02,5.727165564894676208e-02,1.282732933759689331e-01,-2.521466836333274841e-02,2.955820783972740173e-02,1.098456680774688721e-01,1.531965285539627075e-02,1.689812727272510529e-02,1.349707506597042084e-02,-1.964438408613204956e-01,-1.896839290857315063e-01,-2.588442862033843994e-01,1.450305283069610596e-01,1.833063960075378418e-01,8.351499587297439575e-02,1.259498596191406250e-01,1.798079013824462891e-01,1.458956152200698853e-01,-2.685015201568603516e-01,-2.696278393268585205e-01,-2.523659169673919678e-01,-1.962458342313766479e-01,1.399465557187795639e-02,1.947142481803894043e-01,-2.483125776052474976e-01,-1.405319273471832275e-01,-8.674851059913635254e-02,1.319932639598846436e-01,2.493835538625717163e-01,3.434665501117706299e-01,-2.805813550949096680e-01,-9.728100150823593140e-02,4.548168927431106567e-02,-1.293838918209075928e-01,1.587785333395004272e-01,2.641341388225555420e-01,-5.143887400627136230e-01,-1.251078546047210693e-01,5.593663454055786133e-02,-3.744436502456665039e-01,-8.267702162265777588e-02,7.510969787836074829e-02,-3.327343463897705078e-01,-3.216481208801269531e-02,1.391236782073974609e-01],
  [3.829728960990905762e-01,1.103950813412666321e-01,-1.236282885074615479e-01,7.724560797214508057e-02,-1.770214885473251343e-01,-3.898286521434783936e-01,1.303715258836746216e-01,-7.402032613754272461e-02,-2.170016020536422729e-01,1.683361083269119263e-01,-1.269696056842803955e-01,-3.338932693004608154e-01,3.244886696338653564e-01,-5.087075382471084595e-02,-3.289247155189514160e-01,4.312535822391510010e-01,2.062493003904819489e-02,-2.430483549833297729e-01,2.771563231945037842e-01,-2.416583336889743805e-02,-2.279392629861831665e-01,3.115514516830444336e-01,5.372613295912742615e-02,-1.739683002233505249e-01,2.295519113540649414e-01,-5.868395045399665833e-02,-2.411435395479202271e-01,1.247460320591926575e-01,-1.124146655201911926e-01,-2.307010442018508911e-01,1.964938044548034668e-01,-4.235968366265296936e-02,-1.866386234760284424e-01,2.349246293306350708e-01,-6.724136322736740112e-02,-2.410728633403778076e-01,5.278972536325454712e-02,-1.394388079643249512e-01,-2.299174666404724121e-01,2.678206562995910645e-01,5.005301907658576965e-02,-7.779566198587417603e-02,1.167731657624244690e-01,-6.707531213760375977e-02,-1.546277552843093872e-01,2.632036209106445312e-01,9.658226743340492249e-03,-1.243997812271118164e-01],
  [2.049285545945167542e-02,1.459358185529708862e-01,2.825625240802764893e-01,-4.658711701631546021e-02,8.070730417966842651e-02,1.976879090070724487e-01,-1.724282503128051758e-01,-5.592492222785949707e-02,4.792772233486175537e-02,-2.240821868181228638e-01,-9.588503837585449219e-02,-1.289166044443845749e-03,-1.402094215154647827e-01,9.934727102518081665e-02,2.954460978507995605e-01,-1.558900475502014160e-01,1.415731906890869141e-01,3.198477923870086670e-01,-1.458320617675781250e-01,1.706253737211227417e-02,1.551726311445236206e-01,-9.890383481979370117e-02,-6.222068797796964645e-03,1.429918557405471802e-01,-9.518622606992721558e-02,5.297018587589263916e-02,1.457216739654541016e-01,5.144577622413635254e-01,4.798048436641693115e-01,4.225554764270782471e-01,-5.747091174125671387e-01,-4.994065165519714355e-01,-4.218252599239349365e-01,-1.874688118696212769e-01,-3.416620939970016479e-02,7.012236863374710083e-02,-9.269525855779647827e-02,-1.914510875940322876e-02,1.490748301148414612e-02,-4.373687803745269775e-01,-1.722481995820999146e-01,1.618732325732707977e-02,-7.290504127740859985e-02,8.134980499744415283e-02,2.118925005197525024e-01,-1.869179904460906982e-01,1.419437583535909653e-02,1.899365335702896118e-01],
  [-2.295553982257843018e-01,-1.040858328342437744e-01,-3.633126616477966309e-02,3.297108039259910583e-02,1.123886033892631531e-01,1.586538404226303101e-01,6.261266022920608521e-02,6.356527656316757202e-02,8.499893546104431152e-02,-6.154744327068328857e-02,-1.488637272268533707e-02,6.682665646076202393e-02,4.944346100091934204e-02,1.091117560863494873e-01,2.495901286602020264e-01,-1.257395595312118530e-01,-1.302998363971710205e-01,-3.182893153280019760e-03,-3.201259672641754150e-02,-6.029951572418212891e-02,2.928040921688079834e-04,1.476245224475860596e-01,2.025785297155380249e-01,2.434419989585876465e-01,3.464892134070396423e-02,-7.693369686603546143e-02,-1.868774294853210449e-01,2.808628082275390625e-01,1.785824447870254517e-01,1.394072473049163818e-01,-3.188194632530212402e-01,-3.915660679340362549e-01,-4.278742671012878418e-01,2.042664140462875366e-01,1.061884462833404541e-01,3.445799648761749268e-02,3.948784470558166504e-01,1.816941201686859131e-01,8.893743902444839478e-02,4.497994780540466309e-01,2.385177910327911377e-01,1.144850701093673706e-01,2.367308437824249268e-01,3.157180547714233398e-02,-1.091259941458702087e-01,2.088924944400787354e-01,3.961031883955001831e-02,-7.139492034912109375e-02],
  [-5.009368658065795898e-01,-1.886633187532424927e-01,5.116187036037445068e-02,-1.217209324240684509e-01,1.471000909805297852e-01,3.294254839420318604e-01,-8.002019673585891724e-02,1.069713905453681946e-01,2.262871563434600830e-01,-1.562657356262207031e-01,1.436114460229873657e-01,3.578629791736602783e-01,-2.492227852344512939e-01,1.424593180418014526e-01,4.750902354717254639e-01,-4.962654113769531250e-01,-6.860733777284622192e-02,2.809953689575195312e-01,-3.899566829204559326e-01,-8.924795687198638916e-02,1.596833020448684692e-01,-1.630849689245223999e-01,7.711599022150039673e-02,2.627114355564117432e-01,-1.816943734884262085e-01,-4.958041012287139893e-03,9.210685640573501587e-02,-5.128217488527297974e-02,1.234938055276870728e-01,2.304341346025466919e-01,-2.047827988862991333e-01,-6.423447281122207642e-02,3.116856887936592102e-02,-3.521269187331199646e-02,1.095171943306922913e-01,2.048201858997344971e-01,1.218700315803289413e-02,2.621379494667053223e-02,6.041771546006202698e-02,-4.819279536604881287e-02,-8.476375043392181396e-02,-8.943747729063034058e-02,3.833674266934394836e-02,3.551384806632995605e-02,3.881491348147392273e-02,-1.248173266649246216e-01,-9.307981282472610474e-02,-6.952504813671112061e-02],
  [-2.507050633430480957e-01,-2.665473818778991699e-01,-3.255430459976196289e-01,-3.584062680602073669e-02,-7.243739068508148193e-02,-1.319989264011383057e-01,1.048501729965209961e-01,5.263961479067802429e-02,-8.975276723504066467e-03,1.279355287551879883e-01,9.889449179172515869e-02,7.285236567258834839e-02,2.748713083565235138e-02,-9.391420334577560425e-02,-1.908129006624221802e-01,-3.203043714165687561e-03,-1.743176728487014771e-01,-2.490578591823577881e-01,4.567913338541984558e-02,-1.828769780695438385e-02,-7.758989185094833374e-02,3.980546444654464722e-02,3.603344410657882690e-02,-4.191761836409568787e-02,-6.586512550711631775e-03,-7.041218876838684082e-02,-1.142721101641654968e-01,-5.686935186386108398e-01,-4.588425159454345703e-01,-3.622013628482818604e-01,5.765627026557922363e-01,5.404899120330810547e-01,4.747901856899261475e-01,1.789783537387847900e-01,7.015220820903778076e-02,-2.538623102009296417e-02,2.012083828449249268e-01,1.193272620439529419e-01,6.482207775115966797e-02,5.176598429679870605e-01,2.182326912879943848e-01,9.381201118230819702e-03,1.433135718107223511e-01,-1.811004988849163055e-02,-1.646607667207717896e-01,1.220209226012229919e-01,-6.825759261846542358e-02,-2.474541813135147095e-01],
  [3.369357585906982422e-01,9.344694763422012329e-02,-1.120125055313110352e-01,7.024729996919631958e-02,-1.738553196191787720e-01,-3.719919025897979736e-01,1.159306168556213379e-01,-9.550419449806213379e-02,-2.320540547370910645e-01,1.182228252291679382e-01,-1.673490256071090698e-01,-3.588331937789916992e-01,3.182352781295776367e-01,-2.534302417188882828e-03,-2.149794548749923706e-01,3.821747004985809326e-01,4.539440199732780457e-02,-1.479197293519973755e-01,2.172867655754089355e-01,-5.079039186239242554e-02,-2.082131654024124146e-01,3.591128885746002197e-01,1.095605343580245972e-01,-9.622327983379364014e-02,2.096462398767471313e-01,-1.017466709017753601e-01,-3.069838583469390869e-01,3.582493066787719727e-01,6.996338814496994019e-02,-8.222124725580215454e-02,1.910922303795814514e-02,-2.406531721353530884e-01,-3.936744928359985352e-01,3.072801530361175537e-01,-1.894863136112689972e-02,-2.152530401945114136e-01,1.142382472753524780e-01,-1.333462744951248169e-01,-2.501782476902008057e-01,2.179300934076309204e-01,-3.585865255445241928e-03,-1.228902861475944519e-01,1.356580555438995361e-01,-6.676498800516128540e-02,-1.577857881784439087e-01,2.535031437873840332e-01,-1.893236860632896423e-02,-1.537206768989562988e-01],
  [5.606823787093162537e-02,4.345059022307395935e-02,9.753175079822540283e-02,-2.881942987442016602e-01,-2.053894251585006714e-01,-1.082130596041679382e-01,-1.952193379402160645e-01,-4.594179987907409668e-02,6.958082318305969238e-02,7.889990508556365967e-02,1.553854644298553467e-01,2.097698003053665161e-01,6.242447718977928162e-02,8.353897184133529663e-02,4.917455092072486877e-02,3.328397274017333984e-01,3.511135578155517578e-01,2.571865618228912354e-01,1.831654459238052368e-01,2.217735201120376587e-01,1.934871077537536621e-01,-9.839366376399993896e-02,-1.538186222314834595e-01,-1.785678565502166748e-01,1.451172083616256714e-01,3.294480741024017334e-01,4.992151260375976562e-01,-5.570544600486755371e-01,-3.157202303409576416e-01,-1.581431329250335693e-01,-3.803421556949615479e-02,1.880163550376892090e-01,3.760242760181427002e-01,-4.815502464771270752e-01,-1.976915746927261353e-01,6.240331009030342102e-02,-5.010722279548645020e-01,-1.212546601891517639e-01,1.166373789310455322e-01,-2.469596117734909058e-01,4.460783675312995911e-02,2.168347686529159546e-01,-2.778439819812774658e-01,-4.094350710511207581e-02,1.571720689535140991e-01,-3.147009909152984619e-01,-6.808672100305557251e-02,1.562389582395553589e-01]
  ]
                            

tdnn1Bias = [-1.321816444396972656e-01,
  6.233651190996170044e-03,
  -1.369332671165466309e-01,
  2.237693518400192261e-01,
  8.515976369380950928e-03,
  6.188928708434104919e-02,
  1.738531515002250671e-02,
  -8.234867453575134277e-01]

tdnn2Weight = [
  [-5.185477733612060547e-01,-1.663947254419326782e-01,7.270312309265136719e-02,8.841748237609863281e-01,3.506791293621063232e-01,1.717655807733535767e-01,-1.225828647613525391e+00,-6.291055083274841309e-01,-3.287101686000823975e-01,1.025086864829063416e-01,-2.486370950937271118e-01,-4.517945945262908936e-01,-5.816462635993957520e-01,-1.391928046941757202e-01,-4.006326571106910706e-02,1.156480550765991211e+00,7.162677049636840820e-01,4.286668300628662109e-01,6.420279145240783691e-01,2.217587530612945557e-01,7.550114393234252930e-02,-1.357607096433639526e-01,-4.029488563537597656e-02,5.495712906122207642e-02],
  [-1.180655837059020996e+00,-4.733199477195739746e-01,-2.471414953470230103e-01,-1.354023367166519165e-01,-2.593562006950378418e-01,1.511099375784397125e-02,-1.363061517477035522e-01,4.499286115169525146e-01,5.114076137542724609e-01,1.034780025482177734e+00,5.279290676116943359e-01,3.467212617397308350e-01,6.121860146522521973e-01,5.993213057518005371e-01,2.344070076942443848e-01,4.113396108150482178e-01,-3.689723312854766846e-01,-5.562865138053894043e-01,7.088556140661239624e-02,1.403886242769658566e-03,2.570879757404327393e-01,-1.427694559097290039e+00,-6.109520196914672852e-01,-1.596545875072479248e-01],
  [2.654341161251068115e-01,2.657131850719451904e-01,2.528465688228607178e-01,-9.485715031623840332e-01,-4.686858355998992920e-01,-4.932700395584106445e-01,-3.878162801265716553e-02,-2.751319706439971924e-01,-1.832549870014190674e-01,-1.663997322320938110e-01,-4.174238815903663635e-02,1.004888042807579041e-01,8.282507658004760742e-01,3.391117155551910400e-01,3.550398647785186768e-01,4.014648199081420898e-01,4.021640419960021973e-01,2.946689128875732422e-01,-1.091332674026489258e+00,-6.080703139305114746e-01,-5.818508863449096680e-01,4.474216401576995850e-01,4.001115858554840088e-01,3.891073167324066162e-01]
]

tdnn2Bias = [
  6.865327060222625732e-02,
8.284559473395347595e-03,
5.629163701087236404e-03
]

linearWeight = [
  [-1.248851895332336426e+00,-6.048974990844726562e-01,-7.642015814781188965e-02,1.372466981410980225e-01,1.759437024593353271e-01,2.003498822450637817e-01,2.040572911500930786e-01,1.903344243764877319e-01,1.519102305173873901e-01,-1.310206651687622070e+00,-1.078678131103515625e+00,-7.233003973960876465e-01,-4.426669180393218994e-01,-2.627786695957183838e-01,-1.400008797645568848e-01,-4.684110358357429504e-02,1.244209147989749908e-02,5.671194940805435181e-02,9.458435773849487305e-01,6.219678521156311035e-01,3.608199954032897949e-01,3.003393709659576416e-01,3.396319746971130371e-01,3.859946429729461670e-01,4.275149703025817871e-01,4.678604006767272949e-01,5.136668682098388672e-01],
  [9.717187285423278809e-01,8.187635540962219238e-01,3.435909450054168701e-01,7.877922803163528442e-02,-8.854581415653228760e-02,-2.333739250898361206e-01,-3.926815688610076904e-01,-5.208223462104797363e-01,-5.841025114059448242e-01,9.405745267868041992e-01,7.182233929634094238e-01,2.060974389314651489e-01,-7.557131350040435791e-02,-1.807413846254348755e-01,-2.575445175170898438e-01,-3.445666432380676270e-01,-4.326840639114379883e-01,-4.684995412826538086e-01,2.782559692859649658e-01,1.147447824478149414e-01,2.585664093494415283e-01,2.284266650676727295e-01,1.695212274789810181e-01,1.291651427745819092e-01,1.318195760250091553e-01,1.409122794866561890e-01,1.145444065332412720e-01],
  [-3.266995847225189209e-01,-8.760833144187927246e-01,-7.785701751708984375e-01,-5.987550020217895508e-01,-4.480765759944915771e-01,-3.393459618091583252e-01,-2.309507429599761963e-01,-1.548355519771575928e-01,-1.140515431761741638e-01,9.648268818855285645e-01,7.418861985206604004e-01,6.633591055870056152e-01,5.924707055091857910e-01,5.161004662513732910e-01,4.692776501178741455e-01,4.719587862491607666e-01,4.680226147174835205e-01,4.330621659755706787e-01,-2.273152172565460205e-01,1.752146482467651367e-01,1.105967909097671509e-02,-1.043555215001106262e-01,-1.652762740850448608e-01,-2.174758315086364746e-01,-2.714947462081909180e-01,-3.069434165954589844e-01,-3.360481858253479004e-01],
  [6.038325428962707520e-01,6.622170805931091309e-01,5.113995075225830078e-01,3.827289044857025146e-01,3.606794178485870361e-01,3.723700046539306641e-01,4.195749759674072266e-01,4.853234291076660156e-01,5.462441444396972656e-01,-5.951952934265136719e-01,-3.814313113689422607e-01,-1.461565941572189331e-01,-7.423211634159088135e-02,-7.258028537034988403e-02,-7.173292338848114014e-02,-8.055133372545242310e-02,-4.778046160936355591e-02,-2.127414941787719727e-02,-9.967841506004333496e-01,-9.119271039962768555e-01,-6.304461956024169922e-01,-4.244106411933898926e-01,-3.438775539398193359e-01,-2.976837754249572754e-01,-2.878399193286895752e-01,-3.018294572830200195e-01,-2.921640276908874512e-01]

]

linearBias = [
  1.408432424068450928e-01,
-5.022125244140625000e-01,
1.376637071371078491e-01,
2.237053960561752319e-01
]

mean = torch.Tensor([[-17.3807, -16.5200, -15.5265, -15.2664, -15.2006, -15.1720, -15.1751,
  -15.1608, -15.1437, -15.1383, -15.1341, -15.1486, -15.1632, -15.2005,
  -15.2692],
 [-17.9615, -16.0213, -14.7317, -14.6707, -14.6714, -14.6763, -14.6833,
  -14.6963, -14.7012, -14.7201, -14.7537, -14.7889, -14.8450, -14.9119,
  -15.0060],
 [-18.1989, -16.7999, -15.2963, -14.8153, -14.8227, -14.9165, -14.9963,
  -15.0810, -15.1579, -15.2332, -15.3050, -15.3628, -15.4377, -15.5330,
  -15.6502],
 [-18.8399, -17.4088, -15.7558, -15.2165, -15.1316, -15.1180, -15.1340,
  -15.1774, -15.2381, -15.3056, -15.3951, -15.4849, -15.6030, -15.7380,
  -15.8907],
 [-19.8913, -18.9286, -17.5684, -16.9982, -16.7448, -16.5808, -16.4787,
  -16.4361, -16.4368, -16.4676, -16.5315, -16.6199, -16.7315, -16.8642,
  -17.0125],
 [-20.1148, -19.5872, -18.6370, -18.0022, -17.7255, -17.5637, -17.4730,
  -17.4375, -17.4402, -17.4719, -17.5222, -17.5820, -17.6690, -17.7824,
  -17.9248],
 [-20.7518, -20.3228, -19.5078, -18.9722, -18.8029, -18.7274, -18.7015,
  -18.7057, -18.7222, -18.7546, -18.8080, -18.8648, -18.9373, -19.0241,
  -19.1414],
 [-21.3285, -20.9349, -20.1973, -19.7124, -19.5466, -19.4759, -19.4759,
  -19.5236, -19.5951, -19.6801, -19.7679, -19.8669, -19.9636, -20.0790,
  -20.2284],
 [-21.6778, -21.2864, -20.6107, -20.2009, -20.1031, -20.0528, -20.0631,
  -20.1196, -20.2193, -20.3446, -20.4793, -20.6216, -20.7700, -20.9165,
  -21.0910],
 [-22.1642, -21.8257, -21.2229, -20.8381, -20.7533, -20.6932, -20.6611,
  -20.6772, -20.7276, -20.7946, -20.8827, -20.9904, -21.1257, -21.2776,
  -21.4274],
 [-22.3394, -22.0680, -21.6054, -21.2824, -21.2202, -21.1997, -21.2098,
  -21.2453, -21.3009, -21.3662, -21.4370, -21.5317, -21.6517, -21.7880,
  -21.9156],
 [-22.5829, -22.3872, -21.9910, -21.6820, -21.6296, -21.6193, -21.6423,
  -21.6783, -21.7314, -21.8089, -21.8797, -21.9737, -22.0738, -22.1886,
  -22.3198],
 [-22.7813, -22.8135, -22.8340, -22.6823, -22.6411, -22.6216, -22.6201,
  -22.6380, -22.6641, -22.7000, -22.7427, -22.8161, -22.9048, -22.9967,
  -23.0983],
 [-22.9891, -23.1621, -23.4944, -23.5502, -23.5051, -23.4836, -23.4742,
  -23.4775, -23.4960, -23.5177, -23.5410, -23.5817, -23.6333, -23.6955,
  -23.7547],
 [-23.0161, -23.1214, -23.2840, -23.2080, -23.1249, -23.0961, -23.0852,
  -23.0801, -23.0988, -23.1240, -23.1512, -23.2077, -23.2675, -23.3330,
  -23.4004],
 [-23.3653, -23.4597, -23.4884, -23.3565, -23.2811, -23.2625, -23.2545,
  -23.2407, -23.2599, -23.2781, -23.3093, -23.3638, -23.4195, -23.4836,
  -23.5377]])

std = torch.Tensor([[2.6065, 2.4577, 2.1471, 2.1265, 2.1145, 2.1239, 2.1662, 2.1801, 2.1886,
  2.2017, 2.2134, 2.2304, 2.2359, 2.2537, 2.2818],
 [3.5419, 3.3294, 3.2474, 3.2837, 3.2702, 3.2748, 3.2635, 3.2665, 3.2479,
  3.2526, 3.2787, 3.2791, 3.2936, 3.2955, 3.3019],
 [3.6798, 3.7145, 3.8105, 3.9795, 3.9528, 3.9460, 3.9178, 3.8968, 3.8780,
  3.8554, 3.8496, 3.8319, 3.8142, 3.7895, 3.7708],
 [3.8330, 3.9639, 4.0568, 4.1979, 4.2077, 4.2202, 4.2125, 4.2066, 4.1989,
  4.1752, 4.1656, 4.1469, 4.1328, 4.1163, 4.1113],
 [3.5643, 3.8078, 3.9300, 4.0875, 4.1851, 4.2683, 4.3107, 4.3495, 4.3758,
  4.3853, 4.3868, 4.3841, 4.3709, 4.3697, 4.3598],
 [3.1107, 3.3040, 3.5348, 3.7035, 3.8055, 3.8912, 3.9544, 4.0059, 4.0406,
  4.0645, 4.0808, 4.0938, 4.1088, 4.1111, 4.0823],
 [3.0995, 3.2866, 3.5080, 3.6413, 3.7168, 3.7853, 3.8240, 3.8604, 3.8828,
  3.9027, 3.9316, 3.9345, 3.9269, 3.9146, 3.8968],
 [3.1213, 3.2453, 3.3893, 3.5141, 3.6020, 3.6801, 3.7186, 3.7498, 3.7637,
  3.7726, 3.7787, 3.7820, 3.7662, 3.7522, 3.7437],
 [2.9542, 3.0910, 3.2174, 3.3224, 3.3802, 3.4265, 3.4408, 3.4409, 3.4028,
  3.3512, 3.2888, 3.2418, 3.1942, 3.1374, 3.1040],
 [2.8976, 3.0697, 3.1105, 3.1238, 3.1325, 3.1363, 3.1313, 3.1226, 3.1099,
  3.0890, 3.0547, 3.0086, 2.9595, 2.9091, 2.8653],
 [2.8185, 2.9955, 3.0186, 3.0310, 3.0554, 3.0540, 3.0442, 3.0266, 3.0046,
  2.9771, 2.9379, 2.8894, 2.8279, 2.7738, 2.7387],
 [2.5332, 2.7038, 2.7315, 2.7337, 2.7377, 2.7112, 2.6870, 2.6629, 2.6391,
  2.6125, 2.5811, 2.5421, 2.4932, 2.4465, 2.4032],
 [2.3591, 2.4300, 2.4782, 2.5022, 2.5225, 2.5174, 2.5035, 2.4810, 2.4638,
  2.4441, 2.4320, 2.4117, 2.3739, 2.3331, 2.2888],
 [2.3901, 2.3008, 2.2743, 2.3351, 2.3676, 2.3798, 2.3776, 2.3558, 2.3348,
  2.3088, 2.2903, 2.2711, 2.2370, 2.1829, 2.1388],
 [2.3377, 2.2501, 2.2459, 2.3132, 2.3472, 2.3558, 2.3479, 2.3370, 2.3193,
  2.3042, 2.2802, 2.2431, 2.2089, 2.1555, 2.1161],
 [2.0385, 1.9941, 2.0121, 2.0735, 2.0942, 2.0926, 2.0768, 2.0705, 2.0525,
  2.0430, 2.0189, 1.9965, 1.9597, 1.9171, 1.8914]])

tdnn1Weight = torch.reshape(torch.Tensor(tdnn1Weight), (8, 16, 3))
tdnn2Weight = torch.reshape(torch.Tensor(tdnn2Weight), (3, 8, 3))

model_params = [tdnn1Weight,
                torch.Tensor(tdnn1Bias),
                tdnn2Weight,
                torch.Tensor(tdnn2Bias),
                torch.Tensor(linearWeight),
                torch.Tensor(linearBias)]


with torch.no_grad():
  for i, param in enumerate(model.parameters()):
    print(param.shape, model_params[i].shape)
    param.data = model_params[i]

model.eval()

data_tensor = torch.Tensor(sample)
logged_data = torch.transpose(data_tensor, 0, 1)
if (not logged):
		logged_data = torch.log(data_tensor).max(torch.tensor(-25))
normed_data = logged_data
if (not normed):
  normed_data = (logged_data - mean)/std
inputs = normed_data

curr_input = inputs.reshape([1, 16, 15])
outputs = model(curr_input)
_, predicted = torch.max(outputs.data, 1)

print('outputs', outputs)
print('predicted', predicted)
